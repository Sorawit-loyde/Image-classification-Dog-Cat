{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a7ea9bc"
      },
      "source": [
        "## Dog and Cat Image Classification with Transfer Learning\n",
        "\n",
        "This notebook demonstrates how to build an image classification model to distinguish between dogs and cats using a pre-trained ResNet50 model and transfer learning. We will cover data acquisition, preparation, model building, training, and evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76a83b32"
      },
      "source": [
        "Data Acquisition\n",
        "\n",
        "We begin by downloading the 'Dog and Cat Classification Dataset' from KaggleHub. This dataset contains images of dogs and cats which we will use to train our model. The necessary libraries for image processing, model building, and plotting are also imported."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd44f46b",
        "outputId": "79cfb668-e63b-4755-aaa5-bfd9ae188f45"
      },
      "outputs": [],
      "source": [
        "%pip install kagglehub opencv-python Pillow tensorflow matplotlib scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8f9eb06"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import kagglehub\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1c0d81b"
      },
      "source": [
        "Data Configuration\n",
        "\n",
        "We define key parameters for our image processing and model training:\n",
        "\n",
        "- `data_dir`: Specifies the path to our dataset.\n",
        "- `IMG_SIZE`: Sets the target dimensions for all images to ensure consistency.\n",
        "- `BATCH_SIZE`: Determines the number of samples per gradient update during training.\n",
        "- `SEED`: Ensures reproducibility of our dataset splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1c27e85",
        "outputId": "8adce0de-2636-4054-9344-0fc3c08e12b8"
      },
      "outputs": [],
      "source": [
        "base_dataset_path = kagglehub.dataset_download(\"bhavikjikadara/dog-and-cat-classification-dataset\")\n",
        "if 'base_dataset_path' not in locals():\n",
        "    base_dataset_path = \"/kaggle/input/dog-and-cat-classification-dataset\"\n",
        "data_dir = os.path.join(base_dataset_path, \"PetImages\")\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "SEED = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7272820"
      },
      "source": [
        "Explore the Dataset\n",
        "\n",
        "We load a sample of the dataset using `tf.keras.utils.image_dataset_from_directory` to automatically infer class labels from folder names. Then, we visualize a few images to understand the dataset content and confirm correct loading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "00b53511",
        "outputId": "501417f7-25b9-4ac7-9e80-76b08bca13e4"
      },
      "outputs": [],
      "source": [
        "dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    shuffle=True,\n",
        "    seed=SEED,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "class_names = dataset.class_names\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "for images, labels in dataset.take(1):\n",
        "    for i in range(5):\n",
        "        ax = plt.subplot(1, 5, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02e27cd7"
      },
      "source": [
        "Split Dataset into Training and Validation Sets\n",
        "\n",
        "The dataset is loaded and split into training and validation sets. `tf.keras.utils.image_dataset_from_directory` is used to efficiently load images from the specified directory. We then apply `ignore_errors` to handle any potentially corrupted images gracefully, preventing training interruptions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65185070",
        "outputId": "db5ba322-4113-4ba4-81ae-c3fa39b0c886"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=SEED,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=SEED,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "train_ds = train_ds.apply(tf.data.experimental.ignore_errors())\n",
        "val_ds = val_ds.apply(tf.data.experimental.ignore_errors())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34100237"
      },
      "source": [
        "Optimize Data Pipelining\n",
        "\n",
        "`AUTOTUNE` allows the TensorFlow data pipeline to dynamically tune the number of elements prefetched and processed in parallel. Prefetching overlaps data preprocessing and model execution, significantly improving training performance by keeping the GPU busy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f801b011"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c71343c"
      },
      "source": [
        "Apply Data Augmentation\n",
        "\n",
        "To prevent overfitting and improve model generalization, we apply data augmentation techniques:\n",
        "\n",
        "- `layers.RandomFlip(\"horizontal\")`: Horizontally flips images randomly.\n",
        "- `layers.RandomRotation(0.1)`: Introduces slight rotations within a 10% range.\n",
        "- `layers.RandomZoom(0.1)`: Randomly scales images up or down by up to 10%.\n",
        "\n",
        "These transformations increase the diversity of our training data without collecting new images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5a33ac4"
      },
      "outputs": [],
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e014f505"
      },
      "source": [
        "Transfer Learning with ResNet50\n",
        "\n",
        "We leverage a pre-trained `ResNet50` model, which has been trained on the large ImageNet dataset.\n",
        "\n",
        "- By setting `include_top=False`, we remove its original classification head, allowing us to add our own custom layers.\n",
        "- `weights='imagenet'` initializes the model with weights learned from ImageNet, providing a strong starting point.\n",
        "- `base_model.trainable = False` freezes these pre-trained layers to retain their powerful feature extraction capabilities, while only training our new classification head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86fd7ac6"
      },
      "outputs": [],
      "source": [
        "base_model = ResNet50(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "\n",
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3a079bf"
      },
      "source": [
        "Define Model Architecture\n",
        "\n",
        "Here, we construct our complete model by stacking several layers:\n",
        "\n",
        "- **Input Layer:** Defines the expected shape of our input images (224x224 pixels with 3 color channels).\n",
        "- **Data Augmentation:** Applies the previously defined augmentation transformations to increase data diversity.\n",
        "- **ResNet Preprocessing:** `preprocess_input` standardizes image pixel values (e.g., mean subtraction, scaling) according to the ResNet model's requirements.\n",
        "- **Base Model (ResNet50):** The frozen ResNet50 acts as a feature extractor, providing rich representations of the input images.\n",
        "- **GlobalAveragePooling2D:** Reduces the spatial dimensions of the feature maps, effectively summarizing the features for each image into a single vector.\n",
        "- **Dropout:** A regularization technique that randomly sets a fraction of input units to 0 at each update during training (here, 30%), which helps prevent overfitting.\n",
        "- **Dense Layer:** The final classification layer with a single neuron and 'sigmoid' activation, suitable for binary classification (outputting a probability between 0 and 1 for 'Dog')."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "e4325af5",
        "outputId": "4e853f06-9c97-4b87-fe16-5cceb6896d0e"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential([\n",
        "\n",
        "    layers.Input(shape=(224, 224, 3)),\n",
        "\n",
        "    data_augmentation,\n",
        "\n",
        "    layers.Lambda(preprocess_input),\n",
        "\n",
        "    base_model,\n",
        "\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9746631"
      },
      "source": [
        "Compile the Model\n",
        "\n",
        "The model is compiled with the following settings:\n",
        "\n",
        "- **Optimizer:** `tf.keras.optimizers.Adam(learning_rate=1e-4)` for efficient gradient descent with a small learning rate suitable for transfer learning.\n",
        "- **Loss Function:** `'binary_crossentropy'` is used, which is appropriate for binary classification tasks where the output is a probability.\n",
        "- **Metrics:** `'accuracy'` is chosen to monitor the proportion of correctly classified images during training and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "228f9780",
        "outputId": "b8454a8e-d558-4115-c98f-8efe75acff32"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1178994"
      },
      "source": [
        "Define Callbacks\n",
        "\n",
        "Callbacks are functions that are applied at certain stages of the training procedure. We use:\n",
        "\n",
        "- **`EarlyStopping`**: Monitors a chosen metric (e.g., validation loss) and stops training if it doesn't improve for a specified number of epochs (`patience=3`), restoring the best weights found.\n",
        "- **`ModelCheckpoint`**: Saves the model's weights during training, only keeping the version with the best performance on the validation set, specified by `'best_model.keras'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9a98b06e"
      },
      "outputs": [],
      "source": [
        "model_filename = \"best_model.keras\"\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=3, restore_best_weights=True),\n",
        "    ModelCheckpoint(model_filename, save_best_only=True)\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0560b21c"
      },
      "source": [
        "Train the Model\n",
        "\n",
        "The model is trained using the `fit` method on our `train_ds` and `val_ds` for 3 `epochs`. We include our defined `callbacks` to manage the training process, enabling early stopping and saving the best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b2be31d",
        "outputId": "9491ab7b-e546-4cff-bbcc-9b767b78a24f"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=3,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40be9320"
      },
      "source": [
        "Load and Recompile the Best Model\n",
        "\n",
        "After initial training, we load the best performing model saved by `ModelCheckpoint`. We then recompile it, potentially with a slightly different (often lower) learning rate, to prepare for final evaluation or further fine-tuning. Here, the learning rate is set to `1e-5`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "054a75b8",
        "outputId": "384c4f67-e0cc-4022-eb4d-4c14c3f38a1f"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "import os\n",
        "\n",
        "if 'model_filename' not in locals():\n",
        "    model_filename = \"best_model.keras\"\n",
        "\n",
        "model_path = os.path.join(os.getcwd(), model_filename)\n",
        "\n",
        "model = tf.keras.models.load_model(\n",
        "    model_path,\n",
        "    compile=False,\n",
        "    custom_objects={\n",
        "        \"preprocess_input\": preprocess_input\n",
        "    }\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a731e7d"
      },
      "source": [
        "Evaluate Model Performance\n",
        "\n",
        "We evaluate the model's performance on the validation dataset (`val_ds`) to assess its generalization capabilities on unseen data. The `evaluate` method returns the `loss` and `accuracy` on the validation set, providing a final measure of our model's effectiveness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6e3d46a",
        "outputId": "a3376ccd-868b-4c42-fa6d-d503c657a668"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(val_ds)\n",
        "\n",
        "print(f\"\\nValidation Loss: {loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e211aa6"
      },
      "source": [
        "Make Predictions on New Images\n",
        "\n",
        "This section demonstrates how to use the trained model to classify a new, unseen image:\n",
        "\n",
        "1.  **Select Random Image:** A random image path is chosen from either the 'Cat' or 'Dog' directory.\n",
        "2.  **Load and Preprocess:** The image is loaded, converted to RGB, resized to `IMG_SIZE`, and then converted to a NumPy array. An additional batch dimension is added (`np.expand_dims`), and `preprocess_input` is applied as required by ResNet50.\n",
        "3.  **Make Prediction:** The preprocessed image is fed into the `model.predict()` method.\n",
        "4.  **Interpret Prediction:** The model's output (a probability) is interpreted to determine the predicted class ('Cat' or 'Dog') and a confidence score.\n",
        "5.  **Display Results:** The original image is displayed along with its predicted label, confidence, and actual class for visual verification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81271e88",
        "outputId": "edbb6951-56d8-4d4c-9f02-7b5dfc24268c"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import os\n",
        "\n",
        "cat_dir = os.path.join(data_dir, 'Cat')\n",
        "dog_dir = os.path.join(data_dir, 'Dog')\n",
        "\n",
        "def get_random_image(directory):\n",
        "    all_images = os.listdir(directory)\n",
        "    image_files = [f for f in all_images if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    if not image_files:\n",
        "        raise ValueError(f\"No image files found in {directory}\")\n",
        "    return os.path.join(directory, random.choice(image_files))\n",
        "\n",
        "chosen_dir = random.choice([cat_dir, dog_dir])\n",
        "random_image_path = get_random_image(chosen_dir)\n",
        "\n",
        "img = Image.open(random_image_path).convert('RGB')\n",
        "img = img.resize(IMG_SIZE)\n",
        "img_array = np.array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "preprocessed_img = preprocess_input(img_array)\n",
        "\n",
        "prediction = model.predict(preprocessed_img)\n",
        "\n",
        "predicted_class_index = (prediction > 0.5).astype(int)[0][0]\n",
        "predicted_label = class_names[predicted_class_index]\n",
        "confidence = prediction[0][0] if predicted_class_index == 1 else (1 - prediction[0][0])\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(img)\n",
        "plt.title(f\"Predicted: {predicted_label} ({confidence*100:.2f}%)\\nActual: {os.path.basename(chosen_dir)}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f90885cb"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook has walked through the process of building and training an image classification model using transfer learning with ResNet50. We've covered dataset loading, augmentation, model definition, training with callbacks, and finally, making predictions on new images. This approach is highly effective for image-related tasks, especially when dealing with limited datasets, by leveraging the powerful features learned by models on much larger datasets."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
